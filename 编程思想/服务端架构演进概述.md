> 转摘：[阿里为什么能抗住双 11 ？看完这篇你就明白了！](https://mp.weixin.qq.com/s/FEYI2iyU1nCKZkqJBtvK-g)

双十一来临之际，本文以设计淘宝网的后台架构为例，介绍从一百个并发到千万级并发情况下服务端的架构演进过程。同时列举出每个演进阶段会遇到的相关技术，让大家对架构的演进有一个整体的认知。

文章最后汇总了一些架构设计的原则。

## 一、基本概念

在介绍架构之前，为了避免部分读者对架构设计中的一些概念不了解，下面对几个最基础的概念进行介绍。

### 1.1 什么是分布式

系统中的多个模块在不同服务器上部署，即可称为分布式系统，如 Tomcat 和数据库分别部署在不同的服务器中，或两个相同功能的 Tomcat 分别部署在不同的服务器上。

### 1.2 什么是高可用

系统中部分节点失效时，其他节点能够接替它继续提供服务，则可以认为系统具有高可用性。

### 1.3 什么是集群

一个特定领域的软件部署在多台服务器上并作为一个整体提供一类服务，这个整体称为集群。

如 Zookeeper 中的 Master 和 Slave 分别部署在多态服务器上，共同组成一个整体提供集中配置服务。

在常见的集群中，客户端往往能够连接任意一个节点获得服务，并且当集群中一个节点掉线时，其他节点往往能够自动的接替它继续提供服务，这时候说明集群具有高可用性。

### 1.4 什么是负载均衡

请求发送到系统时，通过某些方式把请求均匀分发到多个节点上，使系统中每个节点能够均匀的处理请求负载，则可认为系统是负载均衡的。

### 1.5 什么是正向代理和反向代理

正向代理一般是在客户端方面设置代理将请求转发出去，实现访问特定资源的方式，如翻墙、VPN 代理等。

反向代理则主要部署服务器端，用于将用户的请求分发到系统中的某台服务器上，对外部请求来说，与之交互的只有代理服务器，对系统内部的服务器则毫无感知。

## 二、演进过程

### 2.1 单机架构

在淘宝最初发布的时候，应用数量与用户都较少，可以把 Tomcat 和数据库部署在同一台服务器上。

此时网站的架构和请求处理如下图所示：

![](http://cnd.qiniu.lin07ux.cn/markdown/1573035947563.png)

当用户访问淘宝网时，首先经过 DNS 服务器把淘宝网的域名转换为实际的 IP 地址，然后通过该 IP 地址访问对应的 Tomcat。

**架构瓶颈**：随着用户数的增长，Tomcat 和数据库之间的竞争资源，单机性能不足以支撑业务。

### 2.2 Tomcat 与数据库分开部署

将 Tomcat 和数据库分别部署在单独的服务器中可以让它们独占服务器资源，显著提升两者各自的性能。

此时架构如下图所示：

![](http://cnd.qiniu.lin07ux.cn/markdown/1573037630247.png)

**架构瓶颈**：随着用户数的增长，数据库的读写性能将成为瓶颈，无法实现撑起高并发量的读写操作。

### 2.3 引入本地缓存和分布式缓存

在 Tomcat 同服务器上或者同 JVM 中增加本地缓存，并在外部增加分布式缓存，将热门商品信息或 HTML 页面等缓存起来。

通过缓存能够把绝大多数的读数据库拦截掉，大大降低数据库的 IO 压力。

此时架构图如下所示：

![](http://cnd.qiniu.lin07ux.cn/markdown/1573037717098.png)

其中涉及的技术包括：使用 Memcached 作为本地缓存，使用 Redis 作为分布式缓存，并涉及到缓存一致性、缓存穿透/击穿、缓存雪崩、热点数据集中失效等问题。

**架构瓶颈**：利用缓存抗住了大部分的访问请求，但随着用户数的增长，并发压力主要落在单机的 Tomcat 上，响应逐渐变慢。

### 2.4 引入反向代理实现负载均衡

在多态服务器上分别部署 Tomcat，并使用反向代理软件(如 Nginx)把请求均匀分发到每个 Tomcat 中。

假设一台 Tomcat 服务器最多能支持 100 个并发，Nginx 最多支持 50000 个并发，那么理论上 Nginx 把请求分发到 500 个 Tomcat 服务器上，就能抗住 50000 个并发。

此时架构图如下图所示：

![](http://cnd.qiniu.lin07ux.cn/markdown/1573037979536.png)

其中涉及的技术包括：Nginx、HAProxy，两者都是工作在网络第七层的反向代理软件，主要支持 HTTP 协议，还会涉及 session 共享、文件上传/下载的问题。

**架构瓶颈**：反向代理使应用服务器可支持的并发量大大增加，但随着并发量的增长，单机的数据库也最终无法抗住，成为新的瓶颈。

### 2.5 数据库读写分离

把数据库划分为读库和写库，并且读库可以设置多个，并利用主从同步机制把写库的数据同步到读库中，对于需要查询最新写入数据的场景，可以通过在缓存中多写一份的方式，利用缓存获取最新数据。

此时架构图如下图所示：

![](http://cnd.qiniu.lin07ux.cn/markdown/1573038225151.png)

其中涉及的技术包括：数据库中间件 Mycat，通过它来组织数据库的读写分离和分库分表，客户端通过它来访问下层数据库，还会涉及数据同步和数据一致性的问题。

**架构瓶颈**：业务逐渐变多，不同业务质检的访问量差距较大，不同业务直接竞争数据库，相互影响性能。

### 2.6 数据库按业务分库

把不同业务的数据保存到不同的数据库中，使业务之间的资源竞争降低，对于访问量大的业务，可以部署更多的服务器来支撑。

> 分库之后会导致跨业务的表无法直接做关联分析，需要通过其他途径来解决。

此时架构图如下图所示：

![](http://cnd.qiniu.lin07ux.cn/markdown/1573090353914.png)

**架构瓶颈**：随着用户数的增长，单机的写库会逐渐达到性能瓶颈。

### 2.7 把大表拆分成小表

数据库的写性能瓶颈会首先出现在数据量增加较快的表中，将一个大表水平拆分成多个小表，每个小表只保存一部分的数据，从而实现数据库写性能的提升。

只要实时操作的表中数据量足够小，请求能够足够均匀的的分发到多态服务器上的小表中，那么数据库就能够通过水平扩展的方式来提高性能。其中前面提到的 Mycat 也支持在大表拆分成小表的情况下的访问控制。

比如，针对评论数据，可按照商品 ID 进行 hash，路由到对应的表中存储；针对支付记录，可按照小时创建表，每个小时表继续拆分成小表，使用用户 ID 或记录编号来路由数据。

此时架构图如下图所示：

![](http://cnd.qiniu.lin07ux.cn/markdown/1573090537854.png)

这种做法显著的增加了数据库运维的难度，对 DBA 的要求较高，数据库设计到这种架构时，已经可以称为分布式数据库了。但这只是一个逻辑的数据库整体，数据库里的不同的组成部分是由不同的组件单独来实现的。如分库分表的管理和请求分发由 Mycat 实现，SQL 的解析由单机的数据库实现，读写分离可能由网关和消息队列来实现，查询结果的汇总可能由数据库接口层来实现等等。

这种架构其实是 MMP(大规模并行处理)架构的一类实现。哭泣开源和商用的 MMP 数据库有不少。开源中比较流行的有：Greenplum、TiDB、PostgreSQL XC、HAWQ 等；商用的有：南大通用的 GBase、睿帆科技的雪球 DB、华为的 LibrA 等。不同的 MMP 数据库的侧重点也不一样，如 TiDB 更侧重于分布式 OLTP 场景，Greenplum 更侧重于分布式 OLAP 场景。

这些 MMP 数据库基本都提供了类似 PostgreSQL、Oracle、MySQL 那样的 SQL 标准支持能力，能把一个查询解析为分布式的查询计划分发到每台机器上并行执行，最终由数据库本身汇总数进行返回。也提供了诸如权限管理、分库分表、事务、数据副本等能力，并且大多数能够支持 100 个节点以上的集群，大大降低了数据库运维的成本，并且使是巨亏也能实现水平扩展。

**架构瓶颈**：数据库和 Tomcat 都能够水平扩展，可以支撑的并发量大幅提高，但随着用户数的继续增长，单机的 Nginx 会成为瓶颈。

### 2.8 使用 LVS 或 F5 来使用多个 Nginx 负载均衡

由于瓶颈在单机的 Nginx，因此无法通过两层或多层的 Nginx 来实现多个 Nginx 的负载均衡。此时就需要更进一步的解决方案。

LVS 和 F5 是工作在网络第四层的负载均衡解决方案，其中

* LVS 是软件系统，运行在操作系统的内核态，可对 TCP 请求或更高层级的网络协议进行转发，因此支持的协议更丰富，并且性能也远高于 Nginx，单机的 LVS 可支持几十万个并发请求的转发。
* F5 是一种负载均衡硬件，与 LVS 提供的能力类似，但性能更高，价格也更昂贵。

由于 LVS 是单机版的软件，若 LVS 所在的服务器宕机则会导致整个后端系统都无法访问，因此需要有备用节点。可使用 Keepalived 软件模拟出虚拟 IP，然后把虚拟 IP 绑定到多台 LVS 服务器上，访问虚拟 IP 时，会被路由器重定向到真实的 LVS 服务器。当 LVS 服务器宕机时，Keepalived 软件会自动更新路由器中的路由表，把虚拟 IP 重定向到另外一台正常的 LVS 服务器，从而达到 LVS 服务器高可用的效果。

此时系统架构图如下所示：

![](http://cnd.qiniu.lin07ux.cn/markdown/1573091507198.png)

此处需要注意的是，上图中从 Nginx 层到 Tomcat 层并不是每一台 Nginx 都可以转发请求到任意一台 Tomcat。实际使用时，可能会是每几个 Nginx 下面接一部分的 Tomcat 机器，这些 Nginx 之间通过 Keepalived 实现高可用。

**架构瓶颈**：由于 LVS 也是单机的，随着并发数增长到几十万时，LVS 服务器最终会达到瓶颈，此时用户数达到千万甚至上亿级别，且分布在不同的地区，与服务器机房距离不同也会导致访问的延迟会明显不同。

### 2.9 通过 DNS 轮询实现 IDC 间的负载均衡

在 DNS 服务器中可配置一个域名对应多个 IP 地址，每个 IP 地址对应到不同的机房里的虚拟 IP。当用户通过域名访问淘宝网站时，DNS 服务器会使用某种策略(如轮询)来选择某个 IP 供用户访问。使用这种方式即可实现机房之间的负载均衡。

此时架构图如下图所示：

![](http://cnd.qiniu.lin07ux.cn/markdown/1573092240770.png)

至此系统可做到机房级别的水平扩展，千万级到亿级的并发量都可以通过增加机房来解决，系统入口处的请求并发量不再是问题。

**架构瓶颈**：随着数据的丰富程度和业务的发展，检索、分析等需求越来越丰富，单单依靠数据库将无法解决如此丰富的需求。

### 2.10 引入 NoSQL 数据库和搜索引擎等技术

当数据库中的数据多到一定的规模时，传统的关系型数据库就不适用于复杂的查询了。

对于统计报表场景，在数据量大的时候不一定能抛出结果，而且在跑复杂查询时也会导致其他查询变慢。对于全文检索、可变数据结构等场景，关系型数据库天生不适用。

因此需要针对特定的场景，引入合适的解决方案。如对于海量文件的存储，可通过分布式文件系统 HDFS 来解决；对于 key-value 类型的数据，可通过 HBase 和 Redis 等方案解决；对于全文检索场景，可通过搜索引擎如 ElasticSearch 解决；对于多维分析场景，可通过 Kylin 或 Druid 等方案解决。

此时系统架构图如下图所示：

![](http://cnd.qiniu.lin07ux.cn/markdown/1573092458759.png)

当然，引入更多组件的同时，会提高系统的复杂度，不同的组件保存的数据也需要同步，需要考虑一致性的问题，需要有更多的运维手段来管理这些组件。

**架构瓶颈**：引入更多组件解决了丰富的需求，业务维度能够极大扩充，随之而来的是一个应用中包含了太多的业务代码，升级迭代将会变得非常困难。

### 2.11 大应用拆分成小应用

将应用按照业务板块来划分成多个小的应用，使得单个应用的职责更清晰，相互之间可以做到独立升级迭代。

此时系统结构图如下所示：

![](http://cnd.qiniu.lin07ux.cn/markdown/1573092817814.png)

这时候应用直接可能会涉及到一些公共配置，可以通过分布式配置中心 Zookeeper 来解决。

**架构瓶颈**：不同应用之间存在共用的模块(如用户登录、鉴权等)，由应用单独管理会导致相同的代码存在多份，导致公共功能升级时全部应用代码都要跟着做升级。

### 2.12 微服务化

将应用系统中的基础功能微服务化，每个微服务负责其专有的功能，不同的业务可以通过调用多个微服务来实现其业务功能。这样可以将系统中需要用到的公共功能抽取出来，避免不同业务中重复实现。

比如，用户管理、仓库管理、支付、鉴权等功能需要被多个应用所使用，将这些功能单独抽取出来进行微服务化，可以让业务功能更清晰简单，而每个微服务都可以由单独的团队来管理。

此时系统架构如下图所示：

![](http://cnd.qiniu.lin07ux.cn/markdown/1573092989986.png)

应用可以通过 HTTP、TCP 或 RPC 请求等多种方式来调用微服务，降低业务和具体功能之间的耦合程度。而且还可以通过 Dubbo、SpringCloud 等框架实现服务治理、限流、熔断、降级等功能，提高服务的稳定性和可用性。

**架构瓶颈**：不通服务的接口访问方式不同，应用代码需要适配多种访问方式才能使用服务。此外，业务应用需要访问服务，而服务之间也可能相互访问，调用链将会变得非常复杂，逻辑变得混乱。

### 2.13 企业服务总线 ESB

通过 ESB 统一进行访问协议转换，屏蔽服务接口的访问差异，应用统一通过 ESB 来访问后端服务，服务与服务之间也通过 ESB 来相互调用，以此降低系统的耦合程度。

此时系统架构图如下图所示：

![](http://cnd.qiniu.lin07ux.cn/markdown/1573093603049.png)

这种通过 ESB 统一服务访问方式的架构就是所谓的 SOA（面向服务）架构。SOA 架构包含了微服务化，它只是将各个微服务的访问方式进行了统一。

**架构瓶颈**：随着应用和服务都会不断变多，应用和服务的部署变得复杂，同一台服务器上部署多个服务还要解决运行环境冲突的问题。此外，对于如大促这类需要动态扩缩容的场景，需要水平扩展服务的性能，就需要在新增的服务上准备运行环境，部署服务等，运维将变得十分困难。

### 2.14 容器化

针对服务部署、运维管理、自动水平扩展问题最好的解决办法就是容器化。

目前最流行的容器化技术是 Docker，最流行的容器管理服务是 Kubernetes(K8S)，应用/服务可以打包为 Docker 镜像，通过 K8S 来动态分发和部署镜像。

此时系统架构图如下图所示：

![](http://cnd.qiniu.lin07ux.cn/markdown/1573093868449.png)

Docker 镜像可理解为一个能运行你的应用/服务的最小的操作系统，里面放着应用/服务的运行代码，运行环境根据实际的需要设置好。
把整个“操作系统”打包为一个镜像后，就可以分发到需要部署相关服务的机器上，直接启动 Docker 镜像就可以把服务起起来，使服务的部署和运维变得简单。

在大促的之前，可以在现有的机器集群上划分出服务器来启动 Docker 镜像，增强服务的性能。大促过后就可以关闭镜像，对机器上的其他服务不造成影响。

**架构瓶颈**：使用容器化技术后服务动态扩缩容问题得以解决，但是机器还是需要公司自身来管理，在非大促的时候，还是需要闲置着大量的机器资源来应对大促，机器自身成本和运维成本都极高，资源利用率低。

### 2.15 云平台化

可以将系统可部署到公有云上，利用公有云的海量机器资源承载系统，解决动态硬件资源的问题。

所谓的云平台，就是把海量机器资源，通过统一的资源管理，抽象为一个资源整体。在云平台上可按需动态申请硬件资源（如 CPU、内存、网络等），并且之上提供通用的操作系统，提供常用的技术组件（如 Hadoop 技术栈，MPP 数据库等）供用户使用，甚至提供开发好的应用。用户不需要关心应用内部使用了什么技术，就能够解决需求（如音视频转码服务、邮件服务、个人博客等）。

此时系统架构图如下图所示：

![](http://cnd.qiniu.lin07ux.cn/markdown/1573094463993.png)

在大促的时间段里，在云平台中临时申请更多的资源，结合 Docker 和 K8S 来快速部署服务，在大促结束后释放资源，真正做到按需付费，资源利用率大大提高，同时大大降低了运维成本。

在云平台中会涉及如下几个概念：

1.	IaaS：基础设施即服务。对应于上面所说的机器资源统一为资源整体，可动态申请硬件资源的层面；
2.	PaaS：平台即服务。对应于上面所说的提供常用的技术组件方便系统的开发和维护；
3.	SaaS：软件即服务。对应于上面所说的提供开发好的应用或服务，按功能或性能要求付费。 
## 三、架构设计经验小结

### 3.1 架构的调整是否必须按照上述演变路径进行？

不是的，以上所说的架构演变顺序只是针对某个侧面进行单独的改进。

在实际场景中，可能同一时间会有几个问题需要解决，或者可能先达到瓶颈的是另外的方面，这时候就应该按照实际问题实际解决。
如在政府类的并发量可能不大，但业务可能很丰富的场景，高并发就不是重点解决的问题，此时优先需要的可能会是丰富需求的解决方案。

### 3.2 对于将要实施的系统，架构应该设计到什么程度？

对于单次实施并且性能指标明确的系统，架构设计到能够支持系统的性能指标要求就足够了，但要留有扩展架构的接口以便不备之需。

对于不断发展的系统，如电商平台，应设计到能满足下一阶段用户量和性能指标要求的程度，并根据业务的增长不断的迭代升级架构，以支持更高的并发和更丰富的业务。

### 3.3 服务端架构和大数据架构有什么区别？

所谓的“大数据”其实是海量数据采集清洗转换、数据存储、数据分析、数据服务等场景解决方案的一个统称，在每一个场景都包含了多种可选的技术。如数据采集有 Flume、Sqoop、Kettle 等，数据存储有分布式文件系统 HDFS、FastDFS，NoSQL 数据库 HBase、MongoDB 等，数据分析有 Spark 技术栈、机器学习算法等。

总的来说大数据架构就是根据业务的需求，整合各种大数据组件组合而成的架构，一般会提供分布式存储、分布式计算、多维分析、数据仓库、机器学习算法等能力。而服务端架构更多指的是应用组织层面的架构，底层能力往往是由大数据架构来提供。

### 3.4 有没有一些架构设计的原则？

* N+1 设计：系统中的每个组件都应做到没有单点故障；
* 回滚设计：确保系统可以向前兼容，在系统升级时应能有办法回滚版本；
* 禁用设计：应该提供控制具体功能是否可用的配置，在系统出现故障时能够快速下线功能；
* 监控设计：在设计阶段就要考虑监控的手段；
* 多活数据中心设计：若系统需要极高的高可用，应考虑在多地实施数据中心进行多活，至少在一个机房断电的情况下系统依然可用；
* 采用成熟的技术：刚开发的或开源的技术往往存在很多隐藏的 bug，出了问题没有商业支持可能会是一个灾难；
* 资源隔离设计：应避免单一业务占用全部资源；
* 架构应能水平扩展：系统只有做到能水平扩展，才能有效避免瓶颈问题；
* 非核心则购买：非核心功能若需要占用大量的研发资源才能解决，则考虑购买成熟的产品；
* 使用商用硬件：商用硬件能有效降低硬件故障的机率；
* 快速迭代：系统应该快速开发小功能模块，尽快上线进行验证，早日发现问题大大降低系统交付的风险；
* 无状态设计：服务接口应该做成无状态的，当前接口的访问不依赖于接口上次访问的状态。

