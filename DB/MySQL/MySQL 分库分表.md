### 1. 为什么要分库分表

对于一个数据库，如果业务量剧增，它可能就会出现性能瓶颈：

* **磁盘 IO 瓶颈** 业务量剧增，数据库单机磁盘容量会大大增加，拆成多个数据库可以使每个磁盘的使用率大大降低；
* **数据库连接瓶颈** 数据库的连接数是有限的，在高并发的场景下，单机数据库无法扛着大量请求同时访问，拆分成多个库可以将这些连接分散到不同的数据库中。

MySQL InnoDB 存储引起中，单表最多可存储 10 亿级的数据。但是单表中的数据增多的时候会严重影响数据的读写性能。因为 InnoDB 存储引擎采用 B+ 树来组织和存储表中数据，在表中记录数较多（千万级别）的情况下，B+树的层级将会达到 4 层甚至更多，在数据存取的时候都会增加 IO 次数，从而导致读写性能的降低。

从上面的分析可知：

* 分库是为了避免单机系统资源的不足，通过扩充服务器资源来提升数据库性能；
* 分表是为了避免单表数据过多造成 IO 效率降低，通过分散数据来提升表数据存取性能。

也因此，分库是跟随着项目的拆分将不同的功能模块（订单、用户、商品）拆到不同的数据库中，分表则根据情况进行垂直拆分（字段拆分）和水平拆分（数据拆分）来减小单表容量。

### 2. 分表键

分库的处理相对明确，根据业务边界进行数据划分即可。分表时则需要仔细考虑分表键，也就是要从哪个维度对表进行拆分，因为涉及到拆分后如何从多个表中查找和写入数据的问题。

一般数据库表拆分的键应该是这个表或者业务中的唯一键列或为主要数据的列，比如用户 ID 一类的。这样可以将归属于同一种类的数据落在同一个表中，**避免触发全表路由**。

分表后，使用分表键能够很容易的进行查询，但是对于非分表键的查询则需要通过其他一些方式来实现：

* **全表路由**：遍历所有的表，找到符合条件的数据。这会造成读扩散，使所有的分表都被激活，浪费资源，不推荐；
* **ES 查询**：将数据同步到 ES 中，使用 ES 来查询。这虽然会增加数据冗余量，但相对较为高效，**推荐使用**；
* **二级索引**：对非分表键和分表键之间建立二级索引，这样查询时可以先查到对应的分表键，然后再查具体的数据。这适合所查询的非分表键和分表键之间有简单映射关系的情况，且不宜过多。

### 3. 分表策略

垂直分表的核心思想是尽量将关联不大的列进行拆分，使得拆分后每个分表中的字段都是相对内聚的，这种拆分和分库的思路类似，相对清晰简单。

水平分表则需要对表中的数据进行拆分，根据不同的场景和查询需求，需要选择合适的拆分策略，以能更好的提升查询性能，简化业务逻辑。

#### 3.1 range 范围分表

范围策略划分表是最简单的水平分表方式，就是根据分表键的值，将数据划分为一段段的，每一段放在不同的分表中即可。

比如，下图中使用表的主键`order_id`进行分表，每 300 万划分为一个表：

![](https://cnd.qiniu.lin07ux.cn/markdown/1672110720)

当然，除了直接根据分表键的值进行分段划分，也可以按照时间范围来划分，如不同年月的订单放到不同的表中。

range 范围分表的优缺点如下：

* 优点：有利于后续的扩容；
* 缺点：会出现数据热点问题。

进行 range 范围分表时，近期的数据是存放在同一个子表中的，而近期的数据一般都是热点数据，就会造成写入热点和读取热点。

#### 3.2 hash 取模分表

hash 取模是指对路由 key（一般是分表键）做 hash 计算后，再对分表的总数进行取模，然后根据取模的结果将数据分散到对应的分表中。

比如，要将订单表划分为 4 个表，可以对订单 ID 进行取模分表：

![](https://cnd.qiniu.lin07ux.cn/markdown/1672111119)

hash 取模分表的优缺点如下：

* 优点：不会存在明显的热点问题，因为所有数据都是均分到不同的表中；
* 缺点：不适合范围查找，后续扩容较为麻烦。

hash 取模分表后，后续要继续进行扩容增表，就要对之前所有的数据都重新进行 hash 取模处理和数据迁移，否则会造成数据难以定位的问题。

#### 3.3 一致性 hash 分表

为了解决 hash 取模分表的扩容迁移问题，可以参考 Redis Cluster 集群的一致性 hash 解决方案：

* 将全部的 hash 值作为一个首尾相连的圆环；
* 将分表分别对应一个 hash 值，以使其能均匀的落在 hash 圆环上；
* 对数据的路由 key（一般是分表键）进行 hash 计算，确定其在圆环上的位置；
* 从数据 hash 的位置顺时针方向找到第一个分表 hash，确定该分表即为这条数据需要存储的表。

这样后续继续增加分表的时候，并不需要对所有的数据都进行迁移。

### 3.4 range 范围分库 + hash 取模分表

将 range 和 hash 两种分表策略结合起来，可以避免简单的 range 范围分表时出现的数据倾斜（数据热点）问题：

* 使用 range 范围分表方式对整体数据进行分库；
* 在分库中，对表中数据进行 hash 取模分表。

这样，虽然近期的数据依旧会落到同一个库中，但是会由不同的表进行驱动，避免了数据倾斜的问题；另外，因为 range 范围确定后，分库中的数据量也就能确定了，可以选择合适的分表数量进行 hash 取模分表，避免了后续需要进行扩容的问题。

### 4. 分表问题

分库分表之后，原先归属于同一个库、同一个表的数据四散开来，这对数据的查询会造成很多的影响。

#### 4.1 跨库关联问题

跨库 join 的几种解决思路如下：

* **字段冗余** 把需要关联的字段进行冗余，避免关联操作；
* **全局表** 把所有模块都可能会依赖到的一些基础表（即全局表）在每个库中都保存一份；
* **数据抽象同步** 将两个库中需要关联的表进行定时同步汇总，生成新的表，一般可借助`ETL`(Extract/Transform/Load)工具；
* **应用层代码组装** 将 join 操作拆分成多次查询，分别从不同的库中获取数据后，在业务代码中进行计算拼装。

#### 4.2 聚合和排序问题

跨节点的聚合函数(`count/sum`)、排序(`order by`)以及分组(`group by`)等都是同一类问题，一般都需啊哟基于全部数据集合进行计算。

可以分别在各个节点上得到结果后，再在应用程序端进行合并。

#### 4.3 分页问题

* **全局视野法** 从各个数据库节点查到对应结果后，在代码端汇聚再分页。这样的优点是业务无损，精准返回所需数据，确定是会查询过多的数据，增大网络传输时间；

* **标签分页法** 这种方式需要在业务上做妥协，只能上下翻页而不能跳页查询。这样就能根据上一页结果中的最大查询条件值从每个节点中分别取值后再合并过滤后返回，会比前一种方式获取的数据更少。

#### 4.4 分布式 ID 问题

* UUID
* 雪花算法

> 虽然`auto_increment_increment`和`auto_increment_offset`参数能影响数据库的起始自增 ID 和自增步长，但是其使用不便，且属于全局参数，不建议随意修改。

### 5. 分表不停服

1. 编写代理层，增加对应的控制开关，以控制使用新的 DAO 还是老的 DAO；
2. 开启双写，同时向老表和新表中写入数据，并增加新老表数据的比较；
3. 编写脚本将旧表的存量数据迁移到新表中，需要过滤已经存在于新表的数据；
4. 逐步开放新表的读取，并降低旧表的读取量，直至不再从旧表读取，但依旧保持双写；
5. 新表读写都稳定后，停止双写，仅写新表。


