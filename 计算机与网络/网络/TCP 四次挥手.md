> 转摘：[字节一面，被问到两个经典问题！](https://mp.weixin.qq.com/s/sK2caRVxmkXInKcxtDsTVg)

## 一、基础介绍

TCP 连接建立的时候需要三次握手，关闭的时候则需要四次挥手，这是因为 TCP 是全双工模式，在一方关闭的时候，另一方可能还有数据需要继续发送，就需要分成两阶段分别关闭 TCP 连接的两端。

TCP 的四次挥手的状态变化如下图所示：

![](https://cnd.qiniu.lin07ux.cn/markdown/1671534044)

主动关闭方在主动调用`close()`系统调用后，依次进入`FIN_WAIT_1`、`FIN_WAIT_2`、`TIME_WAIT`和`CLOSE`状态，而被关闭方在调用`read()`系统调用得到`EOF`响应后，会依次进入`CLOSE_WAIT`、`LAST_ACK`、`CLOSE`状态。

### 1.2 TIME_WAIT

`TIME_WAIT`状态是主动关闭连接方才会出现的状态，而且该状态会持续 2MSL 时间才会进入到`CLOSE`状态。在 Linux 上，2MSL 的时长是 60 秒，也就是说**主动关闭连接方停留在`TIME_WAIT`的时间为固定的 60 秒**。

进入到`TIME_WAIT`状态说明自身已经主动关闭连接了，而且也接受到对方的关闭连接的`FIN`报文了，那么为什么不能直接进入到`CLOSE`状态关闭连接而要停留在`TIME_WAIT`状态呢？主要有两个原因：

* **保证*被动关闭连接*的一方能被正确的关闭**：四次挥手中，被动关闭连接方发送过来的`FIN`报文是需要主动关闭连接方回复`ACK`报文的，而该`ACK`报文也有可能会丢失。被动关闭连接方在一定时间后没能收到`ACK`响应时，会尝试继续发送`FIN`报文。如果这时主动关闭连接方处于`CLOSE`状态，就会响应`RST`报文而不是`ACK`报文。所以主动关闭连接方需要处于`TIME_WAIT`状态，而不能直接进入到`CLOSE`状态。
* **防止历史连接中的数据被后面相同四元组的连接错误的接受**。TCP 报文会因为路由器异常而“迷路”，在其迷途期间，TCP 发送端可能会因为确认超时而重发这个报文。而迷途的报文在路由器修复后也会被送到最终目的地，这个原来的迷途报文就被成为 lost duplicate。在关闭一个 TCP 连接后，马上又重新建立起一个相同的 IP 地址和端口之间的 TCP 连接，后一个连接被称为前一个连接的化身。此时就可能会出现这种情况：前一个连接的迷途重复报文在前一个连接终止后出现，从而被误解为从属于新的连接。为了避免这种情况，`TIME_WAIT`状态需要持续 2MSL 时间，这样就可以保证当成功建立一个 TCP 连接的时候，来自前一个连接的重复报文已经在网络中消逝了。

### 1.3 CLOSE_WAIT

`CLOSE_WAIT`状态是被动关闭方会经历的状态，而且如果被动关闭方没有调用`close()`来关闭连接，那么就一直不会发出 FIN 报文，从而就一直处于`CLOSE_WAIT`状态。

## 二、TIME_WAIT 状态过多

### 2.1 TIME_WAIT 状态的 TCP 连接过多的危害

过多的 TIME_WAIT 状态主要的危害主要就是占用各种系统资源：**文件描述符、内存资源、CPU 资源、端口资源**等。系统的端口资源也是有限的，一般可以开启的端口为 32768～61000，也可以通过`net.ipv4.ip_local_port_range`参数来修改 Linux 系统的端口范围。

客户端和服务端 TIME_WAIT 过多造成的影响是不同的：

* 客户端：受限于 TCP 连接的四元组因素，当客户端的 TIME_WAIT 状态过多，占满了所有端口资源，那么就无法对`目的 IP + 目的 Port`都相同的服务端发起连接了，不过还能对其他的服务端发起连接。

* 服务端：服务端的 TIME_WAIT 过多并不会导致端口资源受限，因为服务端只监听一个端口，而客户端的 IP 和 Port 大都不同，所以可以理论上可以建立很多的连接。只是大量的 TIME_WAIT 状态的连接会占用各种系统资源，影响系统性能和稳定性。

### 2.2 优化 TIME_WAIT 状态

TIME_WAIT 状态的持续时间有一点长，显得很不友好，但是他被设计来就是用来避免发生各种意外情况的。《Unix 网络编程》一书中有说：**TIME_WAIT 是我们的朋友，它是有助于我们的，不要试图避免这个状态，而是应该弄清楚它。如果服务端要避免过多的 TIME_WAIT 状态的 TCP 连接，就永远不要主动断开连接，让客户端去断开，由分布在各处的客户端去承受 TIME_WAIT。**

不过，因为各种原因，想要在 Linux 中优化 TIME_WAIT 状态，有如下三种方式：

* 打开`net.ipv4.tcp_tw_reuse`和`net.ipv4.tcp_timestamps`选项；
* `net.ipv4.tcp_max_tw_buckets`
* 程序中使用`SO_LINGER`，强制使用`RST`关闭。

**net.ipv4.tcp_tw_reuse 和 net.ipv4.tcp_timestamps**

开启`net.ipv4.tcp_tw_reuse`可以复用处于 TIME_WAIT 的 socket 为新的连接所用。需要注意的是，*该选项功能只能用在客户端（连接发起方）*。

开启该功能后，在调用`connect()`的时候，内核会随机找一个 TIME_WAIT 状态超过 1 分钟的连接给新的连接复用。

另外，使用这个选项的前提是要打开对 TCP 时间戳（默认开启）的支持：

```
net.ipv4.tcp_tw_reuse = 1
net.ipv4.tcp_timestamps = 1
```

这个时间戳的字段在 TCP 头部的选项部分中，由一共 8 个字节表示时间戳，其中前 4 个字节用来保存发送该数据包的时间，后 4 个字节用来保存最近一次接收对方发送达到数据的时间。

由于引入了时间戳，可以使得重复的数据包因时间戳过期被自然丢弃，因此 TIME_WAIT 状态的连接才能被复用。

**net.ipv4.tcp_max_tw_buckets**

Linux 系统中这个值默认为 18000。当系统中处于 TIME_WAIT 状态的连接数量超过这个值时，系统就会将后面的 TIME_WAIT 状态的连接进行状态重置：

```
net.ipv4.tcp_max_tw_buckets = 18000
```

**程序中使用 SO_LINGER**

可以通过设置 socket 选项来设置调用`close()`关闭连接的行为。

`so_linger`有两个配置项：`l_onoff`和`l_linger`。如果`l_onoff`为非 0 且`l_linger`的值为 0，那么调用`close()`的时候内核会立即发送一个 RST 标志给对端。此时 TCP 连接将跳过四次挥手，直接关闭，自然也就跳过了 TIME_WAIT 状态。

这虽然为跨越 TIME_WAIT 状态提供了一个可能，但这是一个非常危险的行为，不值得提倡。

### 2.3 Web 服务器出现大量的 TIME_WAIT 状态的原因

如果 Web 服务端出现大量的 TIME_WAIT 状态的 TCP 连接，说明服务端主动断开了很多 TCP 连接。在以下场景下，服务端会主动断开 TCP 连接：

1. HTTP 没有使用长连接
2. HTTP 长连接超时
3. HTTP 长连接的请求数量达到上限

**HTTP 没有使用长连接**

从 HTTP/1.1 开始，默认就使用长连接了，而且现在主流使用的就是 HTTP/1.1 和 HTTP/2.0 了，所以一般 Web 服务都是使用长连接的。但是在 HTTP 连接建立后，客户端和服务端任意一方的 HTTP Header 中设置了`Connection: close`信息，就会导致该连接被关闭。

在 RFC 文档中，并没有明确规定由服务端还是客户端主动关闭连接。不过大多数的 Web 服务器的实现中，不管是哪一方禁用了 HTTP Keep-Alive **都是由服务器端主动关闭连接**。此时服务器端上就会出现 TIME_WAIT 状态的连接。

* 客户端禁用了 HTTP Keep-Alive，服务端开启 HTTP Keep-Alive，服务端在发完 HTTP 响应后，就会主动关闭连接。

    HTTP 是请求-响应模型，发起方一直是客户端。HTTP Keep-Alive 的初衷是为客户端后续的请求重用连接。如果在某次 HTTP 请求中，Header 中定义了`Connection: close`信息，那不再重用这个连接的时机就只有在服务端了。所以在 HTTP 请求-响应这个周期的末端关闭连接是合理的。

* 客户端开启了 HTTP Keep-Alive，服务端关闭了 HTTP Keep-Alive，服务端在发完 HTTP 响应后，就会主动关闭连接。

    在服务端主动关闭连接的情况下，主要调用一次`close()`就可以释放连接，剩下的工作由内核 TCP 栈直接进行了处理，整个过程只有一次系统调用；如果要求客户端关闭连接，则服务端在写完最后一个响应之后需要把这个 socket 重新放入到 readable 队列，再次调用`select/epoll`去等待事件，然后调用一次`read()`才能知道连接已经被关闭，这就有两次系统调用了，而且多一次用户端程序被激活执行，socket 保持时间也会更长。
    
因此，**当服务端出现大量的 TIME_WAIT 状态的 TCP 连接的时候，可以排查下是否客户端和服务端都开启了 HTTP Keep-Alive**。因为任意一方没有开启 HTTP Keep-Alive，都会导致服务端在处理完一个 HTTP 请求后，就主动关闭连接。此时服务端上就会出现大量的 TIME_WAIT 状态的 TCP 连接。

**HTTP 长连接超时**

HTTP 长连接的特点时，只要两端都没有明确提出断开连接，则会保持 TCP 连接状态一段时间。为了避免资源浪费的情况，Web 服务器一般会提供一个参数来指定 HTTP 长连接的超时时间，比如 Nginx 提供的`keepalive_timeout`参数。

假设设置了 HTTP 长连接的超时时间是 60 秒，那么 Nginx 会为为连接启动一个定时器，如果客户端在完成一次 HTTP 请求后的 60 秒内没有再发起新的请求，定时器的时间一到 Nginx 就会关闭该连接，此时服务器端上就会出现 TIME_WAIT 状态的 TCP 连接了。

当服务端出现大量的 TIME_WAIT 状态的连接时，如果现象是有大量的客户端建立完 TCP 连接后很长一段时间没有发送数据，那么大概率是因为 HTTP 长连接超时，导致服务端主动关闭连接。

此时可以往网络问题的方向排查，比如是否因为网络问题导致客户端发送的数据一直没有被服务端接收到，以至于 HTTP 长连接超时。

**HTTP 长连接的请求数量达到上限**

Web 服务端通常会有个参数来定义一条 HTTP 长连接上最大能处理的请求数量，当超过最大限制时，就会主动关闭连接。

比如 Nginx 的`keepalive_requests`这个参数，是指一个 HTTP 长连接建立之后能通过其接收并处理的客户端请求的数量。如果在这个长连接上处理的请求的数量达到该参数的值时，Nginx 就会主动关闭这个长连接，从而在服务端出现 TIME_WAIT 状态的 TCP 连接。

Nginx 中`keepalive_requests`的默认值为 100，意味着每个 HTTP 长连接最多只能跑 100 次请求，在 QPS 不是很高的时候，100 是凑合够用的。但是对于一些 QPS 很高的场景（10000 QPS，甚至 30000 QPS），100 的值就不够用了，会导致 Nginx 很频繁的关闭连接，使得服务端出现大量的 TIME_WAIT 状态的 TCP 链接。

这个场景下，解决方式很简单，就是调到请求数量限制的上限值。

## 三、CLOSE_WAIT 状态过多

### 3.1 Web 服务端出现过多的 CLOSE_WAIT 状态的 TCP 连接

**当服务端出现大量 CLOSE_WAIT 状态的连接的时候，说明服务端的程序一直没有调用`close()`来关闭连接。**

一个普通 TCP 服务端的流程为：

1. 创建服务端 socket，bind 绑定端口、listen 监听端口；
2. 将服务端 socket 注册到 epoll；
3. epoll_wait 等待连接到来，并用 accept 获取已连接的 socket；
4. 将已连接的 socket 注册到 epoll
5. epoll_wait 等待读事件发生
6. 对方关闭连接时，我方调用 close。

从这个流程中可以看出，服务端没有调用`close()`函数的原因可能有：

* 第二步没有做，没有将服务端 socket 注册到 epoll，这样有新连接到来时，服务端没办法感知这个时间，也就无法获取到已连接的 socket，服务端自然就没有机会对 socket 调用`close()`函数了。

    这种情况发生的概率比较小，属于明显的代码逻辑 bug。
    
* 第 3 步没有做，有新连接到来时没有调用 accept 获取该连接的 socket，导致当有大量客户端主动断开连接服务端没有机会对这些 socket 调用`close()`函数。

    发生这种情况可能是因为服务端在执行 accept 之前，代码卡在某一个逻辑或提前抛出了异常。
    
* 第 4 步没有做，通过 accept 获取已连接的 socket 后，没有将其注册到 epoll，导致后续收到 FIN 报文的时候，服务端没办法感知这个事件，自然服务端就没有机会调用 close 函数了。

    发生这种情况可能是因为服务端在将已连接的的 socket 注册到 epoll 之前，代码卡在某一个逻辑或者提前抛出了异常。可以参考下别人解决 CLOSE_WAIT 状态问题的实践文章：[一次 Netty 代码不健壮导致的大量 CLOSE_WAIT 连接原因分析](https://mp.weixin.qq.com/s?__biz=MzU3Njk0MTc3Ng==&mid=2247486020&idx=1&sn=f7cf41aec28e2e10a46228a64b1c0a5c&scene=21#wechat_redirect)。

* 第 6 步没有做，当发现客户端关闭连接后，服务端并没有执行 close 函数。

    这可能是因为代码漏处理，或者是在执行 close 函数之前，代码卡在某一个逻辑中，比如发生死锁等。
    
可以发现，当服务端出现大量 CLOSE_WAIT 状态的连接的时候，通常都是代码的问题。这就需要针对具体的代码一步步的进行排查和定位，主要分析方向就是找服务端为什么没有调用`close()`。


